from typing import Any

import random

import numpy as np
import numpy.typing as npt
import polars as pl

from atomea.containers import Project


class DataValidator:
    """
    A utility class to validate the structure, types, and content of data
    within a Project and its Ensembles.

    This validator is crucial for both verifying correctly generated synthetic data
    and for asserting expected behavior during fuzzing (e.g., ensuring malformed
    data is correctly rejected or handled).

    TODO: We should enforce validation in the Data class, but kicking the can for now.
    """

    def __init__(
        self,
        project: Project,
        reference_data: dict[str, Any],
        expect_fuzzed_data: bool = False,
    ):
        """
        Initializes the DataValidator with a Project instance and reference data.

        Args:
            project: The Project instance containing the data to validate.
            reference_data: A dictionary containing the expected data, typically
                            generated by SyntheticAtomDataGenerator.
            expect_fuzzed_data: If True, some validations might be relaxed or
                                specific error conditions might be expected,
                                indicating a fuzzing scenario.
        """
        self.project = project
        self.reference_data = reference_data
        self.expect_fuzzed_data = expect_fuzzed_data

        self.ens_id = reference_data["ens_id"]
        self.run_id = reference_data["run_id"]
        self.ensemble = self.project.get_ensemble(self.ens_id)
        if self.ensemble is None:
            raise ValueError(f"Ensemble '{self.ens_id}' not found in project.")

    def _validate_array_data(
        self,
        data: npt.NDArray[Any],
        expected_shape: tuple[int, ...],
        expected_dtype: np.dtype | npt.DTypeLike,
        name: str,
        n_atoms: int,
        n_frames: int,
        check_nan_inf: bool = True,
        min_val: float | None = None,
        max_val: float | None = None,
    ):
        """Helper to validate common properties of NumPy array data."""
        assert isinstance(data, np.ndarray), f"{name} data is not a NumPy array."

        if (
            not self.expect_fuzzed_data or random.random() < 0.9
        ):  # Allow shape/dtype fuzzing to pass sometimes
            # Shape validation (flexible for fuzzing)
            assert data.shape == expected_shape, (
                f"Incorrect shape for {name}: Expected {expected_shape}, got {data.shape}"
            )

            # # Dtype validation (flexible for fuzzing)
            # # Use np.issubdtype for more robust checks for string dtypes
            # if np.issubdtype(expected_dtype, np.dtype(np.str_)):
            #     assert (
            #         np.issubdtype(data.dtype, np.dtype(np.str_))
            #         or data.dtype == object
            #         or isinstance(data.dtype, pl.String)  # Added this line
            #     ), f"Incorrect dtype for {name}: Expected string-like, got {data.dtype}"
            #     if data.dtype == object:  # If object array, check elements are strings
            #         assert all(isinstance(x, str) for x in data.flatten()), (
            #             f"{name} object array contains non-string elements."
            #         )
            # else:
            #     assert data.dtype == expected_dtype, (
            #         f"Incorrect dtype for {name}: Expected {expected_dtype}, got {data.dtype}"
            #     )

        if check_nan_inf and np.issubdtype(data.dtype, np.floating):
            assert not np.isnan(data).any(), f"NaN values found in {name}."
            assert not np.isinf(data).any(), f"Inf values found in {name}."

        if min_val is not None:
            assert np.all(data >= min_val), (
                f"Values in {name} are below expected min {min_val}."
            )
        if max_val is not None:
            assert np.all(data <= max_val), (
                f"Values in {name} are above expected max {max_val}."
            )

    def validate_coordinates(self) -> None:
        """Validates the atomic coordinates."""
        coords = self.ensemble.coordinates.read(run_id=self.run_id)
        ref_coords = self.reference_data["ref_coords"]
        n_frames = self.reference_data["n_frames"]
        n_atoms = self.reference_data["n_atoms"]

        self._validate_array_data(
            coords,
            expected_shape=(n_frames, n_atoms, 3),
            expected_dtype=np.float64,
            name="Coordinates",
            n_atoms=n_atoms,
            n_frames=n_frames,
            min_val=self.reference_data.get("coord_min"),
            max_val=self.reference_data.get("coord_max"),
            check_nan_inf=not self.expect_fuzzed_data,  # Only check for NaN/Inf if not expecting fuzzed data
        )
        if not self.expect_fuzzed_data:
            assert np.allclose(coords, ref_coords), (
                "Coordinates do not match reference data."
            )

    def validate_atomic_numbers(self) -> None:
        """Validates atomic numbers."""
        atomic_numbers = self.ensemble.topology.atoms.atomic_numbers.read(
            run_id=self.run_id
        )
        ref_atomic_numbers = self.reference_data["ref_atomic_numbers"]
        n_atoms = self.reference_data["n_atoms"]

        self._validate_array_data(
            atomic_numbers,
            expected_shape=(n_atoms,),
            expected_dtype=np.uint8,
            name="Atomic Numbers",
            n_atoms=n_atoms,
            n_frames=1,  # N/A for 1D arrays
            min_val=1,  # Atomic numbers are positive
            max_val=255
            if np.uint8 == atomic_numbers.dtype
            else None,  # Max for uint8, or leave unbounded
        )
        if not self.expect_fuzzed_data:
            assert np.all(atomic_numbers == ref_atomic_numbers), (
                "Atomic numbers do not match reference data."
            )

    def validate_atom_symbols(self) -> None:
        """Validates atom symbols."""
        symbols = self.ensemble.topology.atoms.symbols.read(run_id=self.run_id)
        ref_symbols = self.reference_data["ref_symbols"]
        n_atoms = self.reference_data["n_atoms"]

        # For string arrays, we expect a NumPy array that holds strings.
        # np.array(['H', 'C']) can result in dtype='<U1' or dtype=object.
        # We need to be flexible for now given the `np.array(list[str])` behavior.
        self._validate_array_data(
            symbols,
            expected_shape=(n_atoms,),
            expected_dtype=np.str_,  # Check if it's string-like
            name="Atom Symbols",
            n_atoms=n_atoms,
            n_frames=1,  # N/A for 1D arrays
            check_nan_inf=False,  # Not applicable for strings
        )
        if not self.expect_fuzzed_data:
            assert np.array_equal(symbols, np.array(ref_symbols)), (
                "Atom symbols do not match reference data."
            )
            assert all(len(s) > 0 for s in symbols), (
                "Atom symbols contain empty strings."
            )

    def validate_atom_types(self) -> None:
        """Validates atom types."""
        types = self.ensemble.topology.atoms.types.read(run_id=self.run_id)
        ref_types = self.reference_data["ref_types"]
        n_atoms = self.reference_data["n_atoms"]

        self._validate_array_data(
            types,
            expected_shape=(n_atoms,),
            expected_dtype=np.str_,  # Check if it's string-like
            name="Atom Types",
            n_atoms=n_atoms,
            n_frames=1,  # N/A for 1D arrays
            check_nan_inf=False,
        )
        if not self.expect_fuzzed_data:
            assert np.array_equal(types, np.array(ref_types)), (
                "Atom types do not match reference data."
            )
            assert all(len(s) > 0 for s in types), "Atom types contain empty strings."

    def validate_molecule_ids(self) -> None:
        """Validates molecule IDs."""
        mol_ids = self.ensemble.topology.ids.molecules.read(run_id=self.run_id)
        ref_mol_ids = self.reference_data["ref_mol_ids"]
        n_atoms = self.reference_data["n_atoms"]

        self._validate_array_data(
            mol_ids,
            expected_shape=(n_atoms,),
            expected_dtype=np.uint32,
            name="Molecule IDs",
            n_atoms=n_atoms,
            n_frames=1,  # N/A for 1D arrays
            min_val=0,  # IDs typically start from 0 or 1
            max_val=2**32 - 1 if np.uint32 == mol_ids.dtype else None,
        )
        if not self.expect_fuzzed_data:
            assert np.all(mol_ids == ref_mol_ids), (
                "Molecule IDs do not match reference data."
            )
            # Check for contiguity and range, assuming they start from 0
            if n_atoms > 0:
                unique_ids = np.unique(mol_ids)
                assert unique_ids[0] == 0 or unique_ids[0] == 1, (
                    "Molecule IDs should start from 0 or 1."
                )
                # Check for contiguity (no missing IDs in sequence)
                assert np.all(np.diff(unique_ids) <= 1), (
                    "Molecule IDs are not contiguous."
                )
                assert unique_ids.max() == mol_ids.max(), (
                    "Max unique mol ID does not match max mol ID"
                )

    def validate_component_ids(self) -> None:
        """Validates component IDs."""
        comp_ids = self.ensemble.topology.ids.components.read(run_id=self.run_id)
        ref_comp_ids = self.reference_data["ref_comp_ids"]
        n_atoms = self.reference_data["n_atoms"]

        self._validate_array_data(
            comp_ids,
            expected_shape=(n_atoms,),
            expected_dtype=np.uint32,
            name="Component IDs",
            n_atoms=n_atoms,
            n_frames=1,  # N/A for 1D arrays
            min_val=0,  # IDs typically start from 0 or 1
            max_val=2**32 - 1 if np.uint32 == comp_ids.dtype else None,
        )
        if not self.expect_fuzzed_data:
            assert np.all(comp_ids == ref_comp_ids), (
                "Component IDs do not match reference data."
            )
            # Check for contiguity and range
            if n_atoms > 0:
                unique_ids = np.unique(comp_ids)
                assert unique_ids[0] == 0 or unique_ids[0] == 1, (
                    "Component IDs should start from 0 or 1."
                )
                assert np.all(np.diff(unique_ids) <= 1), (
                    "Component IDs are not contiguous."
                )
                assert unique_ids.max() == comp_ids.max(), (
                    "Max unique comp ID does not match max comp ID"
                )

    def validate_component_labels(self) -> None:
        """Validates component labels."""
        comp_labels = self.ensemble.topology.labels.components.read(run_id=self.run_id)
        ref_comp_labels = self.reference_data["ref_comp_labels"]
        n_atoms = self.reference_data["n_atoms"]

        self._validate_array_data(
            comp_labels,
            expected_shape=(n_atoms,),
            expected_dtype=np.str_,  # Check if it's string-like
            name="Component Labels",
            n_atoms=n_atoms,
            n_frames=1,  # N/A for 1D arrays
            check_nan_inf=False,
        )
        if not self.expect_fuzzed_data:
            assert np.array_equal(comp_labels, np.array(ref_comp_labels)), (
                "Component labels do not match reference data."
            )
            assert all(len(s) > 0 for s in comp_labels), (
                "Component labels contain empty strings."
            )

    def validate_energy_data(self) -> None:
        """Validates the energy Polars DataFrame."""
        energy_df = self.project.energy.potential_mm.read(run_id=self.run_id)
        ref_energy_df = self.reference_data["ref_energy_df"]
        n_frames = self.reference_data["n_frames"]
        ens_id = self.reference_data["ens_id"]
        run_id = self.reference_data["run_id"]

        assert isinstance(energy_df, pl.DataFrame), (
            "Energy data is not a Polars DataFrame."
        )

        if not self.expect_fuzzed_data:
            assert energy_df.shape == ref_energy_df.shape, (
                f"Energy DataFrame shape mismatch: Expected {ref_energy_df.shape}, got {energy_df.shape}"
            )
            assert energy_df.columns == ref_energy_df.columns, (
                f"Energy DataFrame column mismatch: Expected {ref_energy_df.columns}, got {energy_df.columns}"
            )

            # Validate specific columns
            assert "ens_id" in energy_df.columns, (
                "'ens_id' column missing in energy data."
            )
            assert "run_id" in energy_df.columns, (
                "'run_id' column missing in energy data."
            )
            assert "micro_id" in energy_df.columns, (
                "'micro_id' column missing in energy data."
            )
            assert "potential_mm" in energy_df.columns, (
                "'potential_mm' column missing in energy data."
            )

            # Check values
            assert all(energy_df["ens_id"] == ens_id), (
                "Incorrect 'ens_id' in energy data."
            )
            assert all(energy_df["run_id"] == run_id), (
                "Incorrect 'run_id' in energy data."
            )

            # Microstate IDs should be contiguous and match frame count
            assert np.array_equal(
                energy_df["micro_id"].to_numpy(), np.arange(n_frames)
            ), "Microstate IDs in energy data are not contiguous or incorrect."

            # Data types for numeric columns
            assert energy_df["potential_mm"].dtype == pl.Float64, (
                "Potential energy dtype is not Float64."
            )

            # Check content against reference
            assert np.allclose(
                energy_df["potential_mm"].to_numpy(),
                ref_energy_df["potential_mm"].to_numpy(),
            ), "Potential energy values do not match reference."

    def validate_all_data(self) -> None:
        """
        Runs all validation checks on the Project and its Ensemble data.
        """
        # Ensure ensemble and project structure is as expected
        assert self.project.get_ensemble(self.ens_id) is not None, (
            f"Ensemble {self.ens_id} not found."
        )
        assert self.ensemble.label == self.ens_id, "Ensemble label mismatch."

        # Validate atom count consistency
        n_atoms_coords = self.ensemble.coordinates.read(run_id=self.run_id).shape[1]
        n_atoms_atomic_numbers = self.ensemble.topology.atoms.atomic_numbers.read(
            run_id=self.run_id
        ).shape[0]
        assert (
            n_atoms_coords == n_atoms_atomic_numbers == self.reference_data["n_atoms"]
        ), "Atom count inconsistency across data types or with reference."

        # Validate frame count consistency
        n_frames_coords = self.ensemble.coordinates.read(run_id=self.run_id).shape[0]
        assert n_frames_coords == self.reference_data["n_frames"], (
            "Frame count inconsistency between coordinates and reference."
        )

        # Check if energy table exists and has correct number of frames
        energy_df_read = self.project.energy.potential_mm.read(run_id=self.run_id)
        assert energy_df_read.shape[0] == self.reference_data["n_frames"], (
            "Energy DataFrame row count does not match number of frames."
        )

        self.validate_coordinates()
        self.validate_atomic_numbers()
        self.validate_atom_symbols()
        self.validate_atom_types()
        self.validate_molecule_ids()
        self.validate_component_ids()
        self.validate_component_labels()
        self.validate_energy_data()
